{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e3df52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c37660de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2) (1, 2) (2, 1) (1, 1)\n"
     ]
    }
   ],
   "source": [
    "# Layer 1\n",
    "\"\"\"\n",
    "Input = (1x2), weights is (2x2), output of first layer is (1x2). We add a bias to this, same shape\n",
    "(1x2). \n",
    "\"\"\"\n",
    "X = np.array([[2,4]]) # input\n",
    "W1 = np.array([[1, 2], [3, 4]]) #2x2\n",
    "b1 = np.array([[1,1]]) # 1x2\n",
    "\n",
    "\n",
    "\n",
    "# Layer 2\n",
    "\"\"\"Input is the output of layer 1, therefore we have an input of (1x2). We have weights (2x1), output is thus \n",
    "(1x1), to which we add a bias, shape (1x1).\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Define the activated output of layer 1 as the input of layer 2\n",
    "# a = np.array([[a1, a2]])\n",
    "\n",
    "\n",
    "W2 = np.array([[2], [1]])\n",
    "b2 = np.array([[1]])\n",
    "\n",
    "# Print the shapes\n",
    "print(W1.shape, b1.shape, W2.shape, b2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03ab0538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomize the weights to have random values between -1 and 1, if using tanh()\n",
    "# np.random.rand gives values between 0 and 1, thus by shifting we get -1 to 1.\n",
    "W1 = 2*np.random.rand(2,2)-1\n",
    "\n",
    "# For sigmoid have values between 0 and 1\n",
    "W1 = np.random.rand(2,2)\n",
    "W2 = np.random.rand(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "242264d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to forward information from layer 1 to layer 2\n",
    "\"\"\"sigmoidf(x dot W1 + b1)\"\"\"\n",
    "def sigmoidf(x):\n",
    "    \"\"\"Sigmoid always returns a value between 0 and 1\"\"\"\n",
    "    return (1 + np.exp(-x)) ** -1\n",
    "\n",
    "# output layer 1:\n",
    "a1 = sigmoidf(np.dot(X, W1)+b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f40dff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.98128568, 0.99572291]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a167849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.92766109]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# second layer\n",
    "y = sigmoidf(np.dot(a1, W2)+b2)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b402754a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define network\n",
    "def XOR_net(X, W1, W2, b1, b2):    \n",
    "    a1 = sigmoidf(np.dot(X, W1)+b1)\n",
    "    a2 = sigmoidf(np.dot(a1, W2)+b2)\n",
    "    return a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65c85ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.73979027]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Garbage output - no training yet\n",
    "XOR_net(np.array([[0,0]]), np.random.rand(2,2), np.random.rand(2,1), np.array([1,1]), np.array([[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8103decd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.57850845, 0.21806654, 1.        ],\n",
       "       [0.28870781, 0.05477251, 1.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def random_weights(depth):\n",
    "    \"\"\"Create 'weights' per non-input node, first 2 are random, last is bias of value 1\"\"\"\n",
    "    weights = np.random.rand(1,2)\n",
    "    weights = np.append(weights, 1)\n",
    "    for i in range(depth-1):\n",
    "        weights = np.append(weights, np.random.rand(1,2))\n",
    "        weights = np.append(weights, 1)\n",
    "    return weights\n",
    "\n",
    "# test\n",
    "random_weights(3)\n",
    "\n",
    "# to get shape 2x3\n",
    "random_weights(3)[:6].reshape(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "536e3c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using what is asked in the exercise\n",
    "def XOR_net_V2(inputs, weights):   \n",
    "    \"\"\"\n",
    "    Inputs: array \n",
    "    weights: (1x9) matrix, the non-input nodes each have 3 weights, 2 incoming, and a bias.\n",
    "    weights is created in such a way that the first 2 are the (random) weights and the last is the bias\n",
    "    of node 1, 2 or final.\n",
    "    \"\"\"\n",
    "    # Output of first layer, activated\n",
    "    a1 = sigmoidf(np.dot(inputs, weights[:6].reshape(2,3)))\n",
    "    # Output of second layer, activated\n",
    "    a2 = sigmoidf(np.dot(a1, weights[6:].reshape(3,1)))\n",
    "    return a2.reshape((1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05ead267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.74288528])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example\n",
    "XOR_net_V2(np.array([[1,0]]), random_weights(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9bfed39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the error function - use the mean squared error\n",
    "def mse(weights, inputs, outputs, net=XOR_net_V2):\n",
    "    # Calculate the mean squared error over all input and outputs from our network, we divide by\n",
    "    # the length of the outputs to obtain the mean over all squared errors.\n",
    "    return sum([(net(inpt, weights) - output)** 2 for inpt, output in zip(inputs, outputs)])/len(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0b075f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36323202286885903"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "outputs = np.array([0, 1, 1, 0])\n",
    "\n",
    "# Example\n",
    "mse(random_weights(3), inputs, outputs, net=XOR_net_V2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1e8c94e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the gradient of the mse function, grdmse\n",
    "def grdmse(init_weights, inputs, outputs, net, eps):\n",
    "    \"\"\"Note: this is a lazy gradient, it is not really a true mathematical derivation\"\"\"\n",
    "    # Cost at start of iteration\n",
    "    weight = init_weights\n",
    "    s_mse = mse(weight, inputs, outputs, net=XOR_net_V2)\n",
    "    par_derivs = np.zeros((9))\n",
    "    \n",
    "    # Now wiggle the weights\n",
    "    for j, i in enumerate(weight):\n",
    "        \n",
    "        # Wiggle weight\n",
    "        save = i \n",
    "        weight[j] += eps\n",
    "        \n",
    "        # Compute difference and divide by eps\n",
    "        par_derivs[j] = (mse(weight, inputs, outputs, net=XOR_net_V2) - s_mse)/eps\n",
    "        weight[j] = save\n",
    "        \n",
    "        \n",
    "    #print(mse(weight, inputs, outputs, net=XOR_net_V2))\n",
    "    return par_derivs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d32b1706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(weights, grd, rate):    \n",
    "    for j,i in enumerate(weights):\n",
    "        weights[j] -= rate*grd[j]\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5e76bb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: [0.28449469]\n",
      "After: [0.28287054]\n"
     ]
    }
   ],
   "source": [
    "# Let's do a test run for some random weights\n",
    "weights = random_weights(3)\n",
    "#print(weights)\n",
    "mse1 = mse(weights, inputs, outputs)\n",
    "print(\"Before:\", mse1)\n",
    "grd1 = grdmse(weights, inputs, outputs, XOR_net_V2, 0.1)\n",
    "#print(grd1)\n",
    "learn(weights, grd1, 0.1)\n",
    "print(\"After:\", mse(learn(weights, grd1, 0.1), inputs, outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4fa40464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights before: [0.75224896 0.0487717  1.         0.88764052 0.94369309 1.\n",
      " 0.65188074 0.79927806 1.        ]\n",
      "\n",
      "Inital mse: [0.35636847]\n",
      "Mse after step 10000: [0.02794189]\n",
      "Mse after step 20000: [0.00713357]\n",
      "Mse after step 30000: [0.00404196]\n",
      "Mse after step 40000: [0.00281074]\n",
      "Mse after step 50000: [0.00215083]\n",
      "Mse after step 60000: [0.00174008]\n",
      "Mse after step 70000: [0.00146008]\n",
      "Mse after step 80000: [0.0012571]\n",
      "Mse after step 90000: [0.00110328]\n",
      "Mse after step 100000: [0.00098274]\n",
      "\n",
      "Weights after: [ 6.32500468 -3.97699851  5.34692451 -3.95681898  6.38394552  5.38434373\n",
      " -9.82625934 -9.82429421 13.53159104]\n"
     ]
    }
   ],
   "source": [
    "# Initialize random_weights\n",
    "weights = random_weights(3)\n",
    "print(\"Weights before:\", weights)\n",
    "\n",
    "# Simulate\n",
    "for i in range(1,100000+1):\n",
    "    mse1 = mse(weights, inputs, outputs)\n",
    "    if i == 1:\n",
    "        print(\"\\nInital mse:\", mse1)\n",
    "    grd1 = grdmse(weights, inputs, outputs, XOR_net_V2, 0.1)\n",
    "    weights = learn(weights, grd1, 0.1)\n",
    "    if i % 10000 == 0:\n",
    "        print(f\"Mse after step {i}:\", mse(weights, inputs, outputs))\n",
    "print(\"\\nWeights after:\", weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4ac18d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [0 0] prediction: [0.0448099]\n",
      "Input: [0 1] prediction: [0.97004568]\n",
      "Input: [1 0] prediction: [0.97005582]\n",
      "Input: [1 1] prediction: [0.01136371]\n"
     ]
    }
   ],
   "source": [
    "# Validation of model: \n",
    "for i in inputs:\n",
    "    print(\"Input:\", i, \"prediction:\", XOR_net_V2(i, weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb2acd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1489e25f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
