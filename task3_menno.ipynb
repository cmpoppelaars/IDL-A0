{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 3],\n",
       "       [2, 4]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([0, 1])  # inputs\n",
    "w1 = np.array([[1, 2], [3, 4]]).T\n",
    "b1 = np.array([0, 0])\n",
    "\n",
    "np.dot(w1, x) + b1\n",
    "w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 | 0 = 0.030 [0]\n",
      "0 | 1 = 0.971 [1]\n",
      "1 | 0 = 0.966 [1]\n",
      "1 | 1 = 0.027 [0]\n",
      "final mse: 0.0036457123175088627\n",
      "[[-5.27944364  4.99767172 -2.69384639]\n",
      " [-6.05835988  6.0039733   3.15041741]\n",
      " [ 8.64778262 -8.11234668  3.76172572]]\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return (1 + np.exp(-x)) ** -1\n",
    "\n",
    "\n",
    "def random_weights(shape, min=-1, max=1):\n",
    "    return (max - min) * np.random.random(shape) + min\n",
    "\n",
    "\n",
    "def xor_net(inputs: np.ndarray, weights: np.ndarray):\n",
    "    \"\"\"Simulates a Neural Network for {2, 2, 1} architecture.\n",
    "\n",
    "    Args:\n",
    "        inputs (np.ndarray): 1x2 array representing the input nodes\n",
    "        weights (np.ndarray): 1x9 array representing the weights and biases of the network\n",
    "\n",
    "    Returns:\n",
    "        int: output of the network. Range of values: (0, 1)\n",
    "    \"\"\"\n",
    "    inputs = np.append(inputs, 1)  # add bias `value`\n",
    "    hidden = np.dot(weights[:6].reshape((2, 3)), inputs)\n",
    "    layer1 = sigmoid(hidden)\n",
    "\n",
    "    layer1 = np.append(layer1, 1)  # add bias `value`\n",
    "    final = np.dot(weights[6:], layer1)\n",
    "\n",
    "    return sigmoid(final)\n",
    "\n",
    "\n",
    "def mse(weights, inputs, outputs, net=xor_net):\n",
    "    return sum(\n",
    "        [(net(inpt, weights) - output) ** 2 for inpt, output in zip(inputs, outputs)]\n",
    "    )\n",
    "\n",
    "\n",
    "def grdmse(weights, inputs, outputs):\n",
    "    par_derivs = np.zeros((9))\n",
    "    for inpt, output in zip(inputs, outputs):\n",
    "        inpt = np.append(inpt, 1)\n",
    "        hidden = np.dot(weights[:6].reshape((2, 3)), inpt)\n",
    "        layer1 = np.append(sigmoid(hidden), 1)\n",
    "        final = sigmoid(np.dot(weights[6:], layer1))\n",
    "\n",
    "        # These were derived by hand\n",
    "        t = 2 * (final - output) * final * (1 - final)\n",
    "        par_derivs[6:] += t * layer1\n",
    "        par_derivs[3:6] += t * weights[7] * layer1[1] * (1 - layer1[1]) * inpt\n",
    "        par_derivs[:3] += t * weights[6] * layer1[0] * (1 - layer1[0]) * inpt\n",
    "    return par_derivs\n",
    "\n",
    "\n",
    "def print_test(weights, inputs, outputs):\n",
    "    for inpt, output in zip(inputs, outputs):\n",
    "        print(f\"{inpt[0]} | {inpt[1]} = {xor_net(inpt, weights):.3f} [{output}]\")\n",
    "    print(f\"final mse: {mse(weights, inputs, outputs)}\")\n",
    "\n",
    "\n",
    "def grad_desc(eta=0.01, n_loops: int = 1000):\n",
    "    inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "\n",
    "    outputs = np.array([0, 1, 1, 0])\n",
    "    weights = random_weights((9))\n",
    "\n",
    "    for i in range(n_loops):\n",
    "        weights += -eta * grdmse(weights, inputs, outputs)\n",
    "\n",
    "    print_test(weights, inputs, outputs)\n",
    "    print(weights.reshape((3, 3)))\n",
    "\n",
    "\n",
    "inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "\n",
    "outputs = np.array([0, 1, 1, 0])\n",
    "\n",
    "grad_desc(eta=0.1, n_loops=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.85890938 -0.90908956 -0.81769077]\n",
      " [ 0.47918798  0.51980033  0.00393972]\n",
      " [-0.91870358 -0.89549143  0.7162366 ]]\n",
      "274604\n"
     ]
    }
   ],
   "source": [
    "satisfied = False\n",
    "inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "\n",
    "outputs = np.array([0, 1, 1, 0])\n",
    "\n",
    "\n",
    "def discretize(x):\n",
    "    return 1 if x > 0.5 else 0\n",
    "\n",
    "\n",
    "def test_random():\n",
    "    weights = random_weights((9))\n",
    "    for inpt, output in zip(inputs, outputs):\n",
    "        if discretize(xor_net(inpt, weights)) != output:\n",
    "            return False\n",
    "    print(weights.reshape((3, 3)))\n",
    "    return True\n",
    "\n",
    "\n",
    "i = 0\n",
    "while not test_random():\n",
    "    i += 1\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return (1 + np.exp(-x)) ** -1\n",
    "\n",
    "\n",
    "def dsigmoid(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "\n",
    "def relu(x, a=1):\n",
    "    return a * x if x > 0 else 0\n",
    "\n",
    "\n",
    "def drelu(x, a=1):\n",
    "    return a if x > 0 else 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
